---
\__init\_；_title: 部分最优滤波方法
tags: 最优滤波
key: 2021-05-30
author: tlt18
modify_date: 2021-05-30
# article_header:
#   type: cover
#   image:
#     src: /fig/2021-03-28/image-20210329082727723.png
---

以前我学习过卡尔曼滤波和Gmapping建图方法(粒子滤波)，但是当时看的博文并没让我理解或信服，这次看到一系列相关文章从贝叶斯公式讲起，逐渐推导到卡尔曼滤波、卡尔曼滤波的各种形式和粒子滤波，文章中的推导非常详细，因此在此搬运几篇好文。

<!--more-->

## 1 从概率论到贝叶斯滤波

### 1.1 贝叶斯公式

原作者推导地非常详细，对离散形式和连续形式的贝叶斯公式分别进行推导。

#### 1.1.1 离散随机变量的贝叶斯公式

$$
f_{X \mid Y}(x \mid y)=\frac{f_{X, Y}(x, y)}{f_{Y}(y)}=\frac{f_{Y \mid X}(y \mid x) f_{X}(x)}{\sum_{i=1}^{\infty} f_{Y \mid X}\left(y \mid x_{i}\right) f_{X}\left(x_{i}\right)}, \quad(x, y) \in\left\{x_{i}, y_{j}\right\}, i, j=1,2,3, \cdots
$$

- 第一个等号：条件概率的乘法公式；
- 第二个等号：分子是用另一种形式的条件乘法公式展开，分母使用全概率公式。

#### 1.1.2 连续随机变量的贝叶斯公式

$$
f_{X \mid Y}(x \mid y)=\frac{f_{X, Y}(x, y)}{f_{Y}(y)}=\frac{f_{Y \mid X}(y \mid x) f_{X}(x)}{\int_{-\infty}^{+\infty} f_{Y \mid X}(y \mid x) f_{X}(x) \mathrm{d} x}
$$

- $f_{X}(x)$为先验概率密度；
- $f_{Y\mid X}(y\mid x)$为似然概率密度；
- $f_{X\mid Y}(x\mid y)$为后验概率密度；
- 对于确定的Y，$f_Y(y)=\int_{-\infty}^{+\infty} f_{Y \mid X}(y \mid x) f_{X}(x) \mathrm{d} x$是确定的常数，作为归一化系数。

下面是连续随机变量的贝叶斯公式的说明。

引入条件概率分布函数，给出其定义：


$$
F_{X \mid Y}(x \mid y)=\lim\limits_{\epsilon\to0}P(X \le x \mid y-\epsilon<Y \le y+\epsilon)
$$


利用条件概率的性质：


$$
\begin{align}
F_{X \mid Y}(x \mid y)=&\lim\limits_{\epsilon\to0}P(X \le x \mid y-\epsilon<Y \le y+\epsilon)\\
=&\lim\limits_{\epsilon\to0}\frac{P(X \le x , y-\epsilon<Y \le y+\epsilon)}{P(y-\epsilon<Y \le y+\epsilon)}\\
=&\lim\limits_{\epsilon\to0}\frac{\int_{y-\epsilon}^{y+\epsilon}\int_{-\infty}^{x}f_{X,Y}(u,v)dudv}{\int_{y-\epsilon}^{y+\epsilon}f_Y(v)dv}\\
=&\frac{\int_{-\infty}^{x}f_{X,Y}(u,y)du}{f_Y(y)}
\end{align}
$$


因此可以定义条件概率密度：


$$
f_{X \mid Y}(x \mid y)=\frac{f_{X,Y}(x,y)}{f_Y(y)}
$$


利用边缘分布的定义和条件概率密度定义：


$$
\begin{align}
f_Y(y)=&\int_{-\infty}^{+\infty}f_{X,Y}(x,y)dx\\
=&\int_{-\infty}^{+\infty}f_{Y \mid X}(y \mid x) f_{X}(x)dx
\end{align}
$$


最终连续随机变量的贝叶斯公式得证。

### 1.2 随机变量的函数的分布

我们介绍随机变量函数的分布。

定理1.2.1.1：设函数$g:\mathbb{R}^2\to\mathbb{R}$，考虑光滑映射$T:(x_1,x_2)\to (y_1,y_2)$，有：



$$
\iint_{\Omega_X}g(x_1,x_2)dx_1dx_2=\iint_{\Omega_Y}g(x_1(y_1,y_2),x_2(y_1,y_2))\mid \frac{D(x_1,x_2)}{D(y_1,y_2)}\mid dy_1 dy_2
$$



根据上述定理，我们可以定义Y空间的函数$f(y_1,y_2)$，可以得到$f(y_1,y_2)$在空间$\Omega_Y$的积分和上式相等。

定理1.2.1.2：若随机变量$X_1,X_2$的联合密度为$f(x_1,x_2)$，对于双射$T:(X_1,X_2)\to(Y_1,Y_2)$，可以得到$Y_1,Y_2$的联合概率密度为


$$
f_{Y_1,Y_2}(y_1,y_2)=f(x_1(y_1,y_2),x_2(y_1,y_2))\mid \frac{D(x_1,x_2)}{D(y_1,y_2)}\mid
$$


因此可以得到随机变量和的分布性质：

定理1.2.1.3：设X,Y的联合概率分布为$f(x,y)$，则U=X+Y的概率密度为：


$$
f_U(u)=\int f(v,u-v)dv
$$


由于先验概率和似然函数都是通过原先某个随机变量的某个函数求解得到(分别是状态函数和观测函数)，因此需要利用随机变量函数分布的性质。



### 1.3 贝叶斯滤波

在引出贝叶斯公式后，就可以推导贝叶斯滤波了。

假设k时刻的状态变量为$X_k$，观察值为$y_k$，我们想要求解k时刻的最优估计$\hat{x}_k$。

依据贝叶斯公式，$\hat{x}_k$可以认为在观测$y_k$下，是$X_k\mid Y_k=y_k$后验概率的期望：


$$
\begin{align}
\hat{x}_k =& \mathbb{E}[X_k\mid Y_k=y_k]\\
=& \int x_k f_{X_k \mid Y_k}(x_k \mid y_k)d x_k
\end{align}
$$


因此我们计算的核心是后验概率密度函数$f_{X \mid Y}(x_k \mid y_k)$。

借助贝叶斯公式，我们有：


$$
f_{X_k \mid Y_k}(x_k \mid y_k)=\frac{f_{X_k, Y_k}(x_k, y_k)}{f_{Y_k}(y_k)}=\frac{f_{Y_k \mid X_k}(y_k \mid x_k) f_{X_k}(x_k)}{\int_{-\infty}^{+\infty} f_{Y_k \mid X_k}(y_k \mid x_k) f_{X_k}(x_k) \mathrm{d} x_k}
$$

我们想要知道在观测到$Y_k=y_k$的时候，$X_k=x_k$的概率密度有多大。

我们先求解先验概率$f_{X_k}(x_k)$，它相当于上一次滤波对本次滤波的预测结果；再求解似然函数$f_{Y_k \mid X_k}(y_k \mid x_k)$，它描述了不同状态$x_k$下观测$Y_k$的分布情况。

#### 1.3.1 先验概率$f_{X_k}(x_k)$

首先我需要知道先验概率密度函数$f_{X_k}(x_k)$，它通过$X_{k-1}$预测。

根据状态方程可以得到两者关系：


$$
X_K = f(X_{k-1})+Q_k
$$


其中$Q_k \sim f_{Q_k}(x)$表示过程噪声，和$X_{k-1}$独立。

这时候需要随机变量函数的分布相关的知识，并利用$Q_k$和$X_{k-1}$独立性。

我们可以得到：



$$
f_{X_k}(x_k)=\int f_{Q_k}[x-f(v)]f_{X_{k-1}}(v)dv
$$



其实上面的$f_{X_{k-1}}(v)$最好理解为$f_{X_{k-1}\mid Y_{k-1}}(v \mid y_{k-1})$为上一次预测的后验概率密度函数。



#### 1.3.2 似然函数$f_{Y_k \mid X_k}(y_k \mid x_k)$

接下来解决似然函数$f_{Y_k \mid X_k}(y_k \mid x_k)$。这里用到了观测方程：


$$
Y_k = h(X_k)+R_k
$$


其中$R_k\sim f_{R_k}(x)$是观测噪声，和$X_k$独立。

我们有$Y_k \mid (X_k=x_k) = h(x_k)+R_k$，这里相当于$h(x_k)$成为了一个确定的值，对于概率密度有：


$$
f_{Y_k \mid X_k}(y_k \mid x_k)=f_{R_k}(y_k-h(x_k))
$$


这里也可以理解为随机变量函数分布的求法。

至此，我们得到了似然函数$f_{Y_k \mid X_k}(y_k \mid x_k)$。

#### 1.3.3 状态更新

将先验概率和似然函数带入贝叶斯公式：


$$
\begin{align}
f_{X_k \mid Y_k}(x_k \mid y_k)=&\frac{f_{Y_k \mid X_k}(y_k \mid x_k) f_{X_k}(x_k)}{f_{Y_k}(y_k)}\\
=&\frac{f_{R_k}(y_k-h(x_k))\cdot\int f_{Q_k}[x-f(v)]f_{X_{k-1}}(v)dv}{f_{Y_k}(y_k)}
\end{align}
$$


我们没有求解分母，因为整个式子是$x_k$的函数，观测$y_k$是确定的值，我们只需要对后验概率密度函数$f_{X_k \mid Y_k}(x_k \mid y_k)$作归一化即可。

由此我们完整描述了一遍贝叶斯滤波：

- 基于状态方程的先验概率$f_{X_k}(x_k)=\int f_{Q_k}[x-f(v)]f_{X_{k-1}}(v)dv$；
- 基于观测方程的似然函数$f_{Y_k \mid X_k}(y_k \mid x_k)=f_{R_k}(y_k-h(x_k))$；
- 基于贝叶斯公式的更新$f_{X_k \mid Y_k}(x_k \mid y_k)=\frac{f_{Y_k \mid X_k}(y_k \mid x_k) f_{X_k}(x_k)}{f_{Y_k}(y_k)}$；
- 基于后验期望的估计$
  \hat{x}_k = \int x_k f_{X_k \mid Y_k}(x_k \mid y_k)d x_k$

推导过程中基础的数学知识用到贝叶斯公式、条件概率和随机变量函数的分布。

#### 1.3.4 贝叶斯滤波的缺点

除了数学基础外，引文中还提到了贝叶斯公式的缺点。在求解先验概率、归一化和后验期望时，需要用到无穷积分，实际上很难计算，因此有以下处理方法：

- 对状态转移函数f、观测函数h进行线性假设，过程噪声Q和观测噪声R进行正态分布假设，得到卡尔曼滤波；
- 状态转移函数f或观测函数h非线性，过程噪声Q和观测噪声R进行正态分布假设，得到扩展卡尔曼滤波和无迹卡尔曼滤波；
- 连续转化为离散计算，进行粒子滤波（蒙特卡洛方法）、直方图滤波。

## 2从贝叶斯滤波到卡尔曼滤波




## 3 参考资料

1. [从概率到贝叶斯滤波 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/268624245)
2. [从贝叶斯滤波到卡尔曼滤波 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/268632039)
3. [从贝叶斯滤波到扩展卡尔曼滤波 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/268635367)
4. [从贝叶斯滤波到无迹卡尔曼滤波 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/328541130)
5. [从贝叶斯滤波到粒子滤波 - 知乎 (zhihu.com)](https://zhuanlan.zhihu.com/p/349853929)

